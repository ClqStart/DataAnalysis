{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>belta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001745</td>\n",
       "      <td>0.001164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.017577</td>\n",
       "      <td>0.011717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.033408</td>\n",
       "      <td>0.022270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.049239</td>\n",
       "      <td>0.032819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.065071</td>\n",
       "      <td>0.043364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      alpha     belta\n",
       "0  0.001745  0.001164\n",
       "1  0.017577  0.011717\n",
       "2  0.033408  0.022270\n",
       "3  0.049239  0.032819\n",
       "4  0.065071  0.043364"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "filename = \"/home/qiwsir/Documents/DataAnalysis/chapter05/snell.csv\"     #数据地址\n",
    "datas = pd.read_csv(filename)\n",
    "datas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    datas['alpha'], datas['belta'], test_size=0.4, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 60, 40)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas['alpha'].count(), X_train.count(), X_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f164cc077b8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "c    0.075643\n",
       "x    0.471903\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm    #①\n",
    "X = pd.DataFrame({\"c\": np.ones(60).T, \"x\": X_train})    #②\n",
    "model = sm.OLS(Y_train, X)     #③\n",
    "result = model.fit()    #④\n",
    "result.params     #⑤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1646e21518>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coe = result.params\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X_train, Y_train)\n",
    "x = np.linspace(0, 1.8, 100)\n",
    "y = coe['c'] + coe['x']*x\n",
    "ax.plot(x, y, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c      -0.022771\n",
       "x       0.820724\n",
       "x**2   -0.210711\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " XX_train = pd.DataFrame({\"c\": np.ones(60).T, \"x\":X_train, \"x**2\": X_train*X_train})\n",
    "result2 = sm.OLS(Y_train, XX_train).fit()\n",
    "result2.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1646d9b8d0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coe = result2.params\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X_train, Y_train)\n",
    "x = np.linspace(0, 1.8, 100)\n",
    "y = coe['c'] + coe['x']*x + coe['x**2']*x*x\n",
    "ax.plot(x, y, color='red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.99252036],\n",
       "       [ 0.99252036,  1.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coe = result.params\n",
    "y = coe['c'] + coe['x']*X_test\n",
    "np.corrcoef(y, Y_test)    #计算相关系数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.99929732],\n",
       "       [ 0.99929732,  1.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coe = result2.params\n",
    "y = coe['c'] + coe['x']*X_test + coe['x**2']*X_test*X_test\n",
    "np.corrcoef(y, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>belta</td>      <th>  R-squared:         </th> <td>   0.966</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.965</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1647.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 01 Feb 2018</td> <th>  Prob (F-statistic):</th> <td>2.80e-44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:21:17</td>     <th>  Log-Likelihood:    </th> <td>  105.99</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    60</td>      <th>  AIC:               </th> <td>  -208.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    58</td>      <th>  BIC:               </th> <td>  -203.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>c</th> <td>    0.0756</td> <td>    0.011</td> <td>    6.855</td> <td> 0.000</td> <td>    0.054</td> <td>    0.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x</th> <td>    0.4719</td> <td>    0.012</td> <td>   40.578</td> <td> 0.000</td> <td>    0.449</td> <td>    0.495</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>12.947</td> <th>  Durbin-Watson:     </th> <td>   1.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.002</td> <th>  Jarque-Bera (JB):  </th> <td>   4.770</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.407</td> <th>  Prob(JB):          </th> <td>  0.0921</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.884</td> <th>  Cond. No.          </th> <td>    3.81</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  belta   R-squared:                       0.966\n",
       "Model:                            OLS   Adj. R-squared:                  0.965\n",
       "Method:                 Least Squares   F-statistic:                     1647.\n",
       "Date:                Thu, 01 Feb 2018   Prob (F-statistic):           2.80e-44\n",
       "Time:                        15:21:17   Log-Likelihood:                 105.99\n",
       "No. Observations:                  60   AIC:                            -208.0\n",
       "Df Residuals:                      58   BIC:                            -203.8\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "c              0.0756      0.011      6.855      0.000       0.054       0.098\n",
       "x              0.4719      0.012     40.578      0.000       0.449       0.495\n",
       "==============================================================================\n",
       "Omnibus:                       12.947   Durbin-Watson:                   1.327\n",
       "Prob(Omnibus):                  0.002   Jarque-Bera (JB):                4.770\n",
       "Skew:                          -0.407   Prob(JB):                       0.0921\n",
       "Kurtosis:                       1.884   Cond. No.                         3.81\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.965974637844 0.998641952133\n"
     ]
    }
   ],
   "source": [
    "print(result.rsquared, result2.rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12456375865335403"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy as sp\n",
    "z, p = sp.stats.normaltest(result2.resid.values)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.graphics.api as smg\n",
    "fig, ax = plt.subplots()\n",
    "smg.qqplot(result2.resid, ax=ax)\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1646778198>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.residplot(x=X_train.values, y=result2.resid.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "err = np.random.RandomState(1)\n",
    "x = 10 * err.rand(200)\n",
    "y = 2 * x - 5 + err.randn(200)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope:  1.99154872449\n",
      "intercept:  -4.88227590023\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression    #①\n",
    "model = LinearRegression(fit_intercept=True)    #②\n",
    "model.fit(x_train[:, np.newaxis], y_train)    #③\n",
    "\n",
    "print(\"slope: \", model.coef_[0])\n",
    "print(\"intercept: \", model.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.98499746],\n",
       "       [ 0.98499746,  1.        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_fit = model.predict(x_test[:, np.newaxis])     #①\n",
    "np.corrcoef(y_fit, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f164cbf9f98>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resid = y_test - y_fit\n",
    "sns.residplot(x=x_test, y=resid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(3, include_bias=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   2.,   4.,   8.],\n",
       "       [  1.,   3.,   9.,  27.],\n",
       "       [  1.,   4.,  16.,  64.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([2, 3, 4])\n",
    "poly.fit_transform(x[:, None])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   1.,   4.,   4.],\n",
       "       [  1.,   2.,   5.,  10.],\n",
       "       [  1.,   3.,   6.,  18.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(2, interaction_only=True)\n",
    "x = pd.DataFrame({\"x1\": [1, 2, 3], \"x2\": [4, 5, 6]})\n",
    "poly.fit_transform(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "err = np.random.RandomState(1)\n",
    "x = 10 * err.rand(100)\n",
    "y = np.sin(x) + 0.1 * err.randn(100)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.98994052],\n",
       "       [ 0.98994052,  1.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline    #①\n",
    "model = Pipeline([('poly', PolynomialFeatures(degree=7)), \n",
    "                  ('linear', LinearRegression(fit_intercept=False))])     #②\n",
    "\n",
    "model = model.fit(x_train[:, np.newaxis], y_train)\n",
    "y_fit = model.predict(x_test[:, np.newaxis])\n",
    "\n",
    "np.corrcoef(y_fit, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.sin(math.pi/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.03096889])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[math.pi/2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('Trans1', <__main__.FooTransformer object at 0x7f16448e5b00>), ('Trans2', <__main__.FooTransformer object at 0x7f16448e5ac8>), ('Estmt1', BarEstimator(number=1))])\n",
      "Pipeline(memory=None,\n",
      "     steps=[('footransformer-1', <__main__.FooTransformer object at 0x7f16448e5860>), ('footransformer-2', <__main__.FooTransformer object at 0x7f16448e5588>), ('barestimator', BarEstimator(number=1))])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "class FooTransformer(TransformerMixin):\n",
    "    def __init__(self, number):\n",
    "        self.number = number\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        print(\"Transformer No.{}: fit X={}\".format(self.number, X))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        print(\"Transformer No.{}: transform X={} => X+10={}\".format(self.number, X, X+10))\n",
    "        return X+10\n",
    "\n",
    "class BarEstimator(BaseEstimator):\n",
    "    def __init__(self, number):\n",
    "        self.number = number\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        print(\"Estimator No.{}: fit X={}\".format(self.number, X))\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        print(\"Estimator No.{}: predict X={} is...\".format(self.number, X))\n",
    "        return \"a new result\"\n",
    "p1 = Pipeline(steps=[(\"Trans1\", FooTransformer(1)),\n",
    "                     (\"Trans2\", FooTransformer(2)),\n",
    "                     (\"Estmt1\", BarEstimator(1))])\n",
    "print(p1)\n",
    "\n",
    "p2 = make_pipeline(FooTransformer(1), FooTransformer(2), BarEstimator(1))\n",
    "print(p2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#===== Pipeline fitting =====#\n",
      "Transformer No.1: fit X=100\n",
      "Transformer No.1: transform X=100 => X+10=110\n",
      "Transformer No.2: fit X=110\n",
      "Transformer No.2: transform X=110 => X+10=120\n",
      "Estimator No.1: fit X=120\n",
      "#===== Pipeline predicting =====#\n",
      "Transformer No.1: transform X=100 => X+10=110\n",
      "Transformer No.2: transform X=110 => X+10=120\n",
      "Estimator No.1: predict X=120 is...\n",
      "a new result\n"
     ]
    }
   ],
   "source": [
    "p = Pipeline(steps=[(\"Trans1\", FooTransformer(1)),\n",
    "                     (\"Trans2\", FooTransformer(2)),\n",
    "                     (\"Estmt1\", BarEstimator(1))])\n",
    "print(\"#===== Pipeline fitting =====#\")\n",
    "p.fit(X=100)\n",
    "print(\"#===== Pipeline predicting =====#\")\n",
    "pred = p.predict(X=100)\n",
    "print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
